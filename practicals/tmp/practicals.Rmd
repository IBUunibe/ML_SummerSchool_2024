---
title: "Practicals"
author: "Aparna Pandey, Marco Kreuzer, Stephan Peischl"
date: "2024-06-06"
output: html_document
html_document:
    toc: true
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, echo=FALSE,warning=FALSE,message=FALSE}
# load required libraries
library(dplyr)
library(MASS)
library(monomvn)
library(VIM)
library(naniar)
library(lmtest)
library(ggplot2)
library(GGally)
library(tidyverse) 
library(Rmisc) 
library(tibble) 
library(dplyr)
library(caret)
library(adabag)
library(groupdata2)
library(tidyverse)
library(kableExtra)
library(mlbench)
library(rpart)
library(rpart.plot)
library(patchwork)
```

# Day 1 {.tabset}

## Session 1.1 (Monday)

### Linear Regression / Model Selection

#### Exercise 1: 

Thirteen samples of Portland cement were set. For each sample, the percentages of the four main chemical ingredients was accurately measured (X1 - X4). While the cement was setting the amount of heat evolved was also measured (Y).

**Source:** Woods, H., Steinour, H.H. and Starke, H.R. (1932) Effect of composition of Portland cement on heat evolved during hardening. Industrial Engineering and Chemistry, 24, 1207–1214.

 - Load Cement dataset
 
```{r}
data = cement
```
 
 - Visualize the data, what do you observe? 
 - Perform Linear Regression using all four explanatory variables and describe the results
 - Perform linear regression using only X1 and X2 as explanatory variables
 - Based on the previous results, what do you believe would happen if you use only X3 and X4 as explanatory variables? Would you get siginficant effects or not?
 - What would you get if you use only X1 and X3? 
 - Check your answers by performing the corresponding linear regression models
 
#### Exercise 2: 

We consider the pyrimidine data set. It contains 74 activity measurements of the enzyme DHFR in a bacterium in the presence of different pyrimidines characterized by 26 physico-chemical properties. Those properties are quantified by the variables X1 to X26; the activity of DHFR is the response variable Y.

**Source:** Jonathan D Hirst, Ross D King, and Michael JE Sternberg. Quantitative structure-activity relationships by neural
networks and inductive logic programming. i. the inhibition of dihydrofolate reductase by pyrimidines. Journal of
Computer-Aided Molecular Design, 8(4):405–420, 1994.

- Load the Pyrimidine dataset. 
- Explore the dataset, visualize the data.
- Fit a lineaer regression model and perform variable selection using LRT or AIC. 
- Perform LASSO and compare your results.
- Try to answer the following questions:

  1. What is the optimal range for the regularization parameter $\lambda$?
      + [−5;−3]
      + [0.0001; 0.001]
      + [0.005; 0.05]
      + [0.1; 1]
      + [3; 5]

  2. When choosing $\lambda = 0.018$, how many non-zero coefficients do we get? Write down the model equation.

  3. Assume now that we choose $\lambda$ = 0.05. Which variables remain in the model in this case?

  4. What value would you choose for $\lambda$?
 

## Session 1.2 (Monday)
### Logistic Regression

In a study, survival of prematurely born babies was examined.

Explanatory variables: 
- birth weight (grams),
- age (weeks after procreation), 
- three clinical variables


#### Exercise 2: 
- Load baby dataset 
- Visualize the dataset
- Perform Logistic Regression
- Rank the variables and identify the most important ones
- Do model selection using LRT and AIC
- Perform LASSO analysis on the dataset and compare your results


# Day 2 {.tabset}
## Session 2.1 (Tuesday)
### Decision Trees

#### Exercise 3: 

- Use the baby data set and fit a CART model to the data.
- Choose a cp paramter using cross validation
- Compare the pruned tree to the full tree to see which one works better on new data (i.e., data that was not used to fit the model). How would you do this?



## Session 2.2 (Tuesday)
### Caret pipeline pt.1
#### Exercise 4: 
Use the decision tree example from the previous exercise and write down a pipeline to analyze the data using the CARET package. Make the pipeleine as flexible as possible. 

- split into test and training data
- fit a model using CV
- evaluate model peformance on the test data
- visulaize your results with a confusion matrix
- summarize accuracy measures in a table
- now use a different dataset and apply the pipeline to the dataset 





# Day 4 {.tabset}
## Session 3.1 (Thursday)
### Caret pipeline pt. 2

#### Exercise 4:

Take one of the datasets that we have seen so far and fit several machine learning models to the data. 

- Try to figure out which model works best and visualize the performance of the different models for better comparison (accuracy, misclassification rate, RMSE, confusion matrix, ROC, ...). 
- Extract important variables and compare across models
- Choose the optimal value and justify your choice

## Session 3.2 (Thursday)

### Final Competition

Load the breastcancer data set and try to predict health status from the explanatory variables. 

Features were computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image.


We have selected a validation data set that you will only receive at the end. 

Every group should have one model and we will apply it to the validation data. The best performance will receive a small price.

**Dataset Summary:**

Variables: 

1) ID number
2) Diagnosis (M = malignant, B = benign)

Ten real-valued features are computed for each cell nucleus:

a) radius (mean of distances from center to points on the perimeter)
b) texture (standard deviation of gray-scale values)
c) perimeter
d) area
e) smoothness (local variation in radius lengths)
f) compactness (perimeter^2 / area - 1.0)
g) concavity (severity of concave portions of the contour)
h) concave points (number of concave portions of the contour)
i) symmetry
j) fractal dimension ("coastline approximation" - 1)

The mean, standard error and "worst" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.

**Source:** W. Nick Street, W. H. Wolberg, and O. L. Mangasarian "Nuclear feature extraction for breast tumor diagnosis", Proc. SPIE 1905, Biomedical Image Processing and Biomedical Visualization, (29 July 1993); https://doi.org/10.1117/12.148698

```{r}
# Wisconsin Breast Cancer Database
data(BreastCancer)
head(BreastCancer)
```


