# Machine Learning Tutorials

This repository contains tutorials and teaching material that are part of the 
machine learning summer school 2024, organized by the Interfaculty 
Bioinformatics Unit, University of Bern.

The summer school is an introductory course where a basic level of R is 
required. The main idea is to conceptually understand what machine learning in 
its principles entails and how it may differ from classical statistics. The 
learning objectives are to understand the following principles:

- The fundamental differences between machine learning and classical statistics.
- How to build and evaluate regression models, both linear and logistic.
- The concepts of model selection and regularization techniques, such as LASSO.
- How to implement cross-validation for model evaluation.
- The basics of machine learning pipelines and the use of caret for model training and evaluation.
- An introduction to advanced machine learning methods including decision trees, random forests, boosting, and neural networks.

## Structure

The course is divided into the following conceptual blocks:

### Linear & Logistic Regression (Day 1)
- **Practical 1: Linear Regression: Problems with Correlated Data**
  - Understand the issues that arise when predictor variables are correlated.
  - Learn techniques to identify and mitigate multicollinearity.

- **Practical 2: Linear Regression: Model Selection, Regularization (LASSO), Cross-Validation**
  - Learn how to select the best model using various criteria.
  - Understand regularization techniques such as LASSO.
  - Implement cross-validation to evaluate model performance.

- **Practical 3: Logistic Regression: Classifier, Model Selection, LASSO**
  - Build and evaluate logistic regression models.
  - Understand how to select and regularize logistic regression models.
  - Apply LASSO to logistic regression for feature selection.

### Machine Learning Pipelines
- **Introduction to Decision Trees**
  - Learn the basic principles of decision tree algorithms.
  - Understand how decision trees can be used for both classification and regression tasks.

- **Practical 4: Decision Trees (Baby Dataset)**
  - Apply decision tree algorithms to the baby dataset.
  - Evaluate the performance of decision trees.

- **Introduction to Caret and ML Pipelines**
  - Understand the caret package and its role in streamlining the model training process.
  - Learn how to set up machine learning pipelines for systematic model building.

- **Practical 5: Our First ML Pipeline**
  - Build a complete machine learning pipeline using caret.
  - Implement preprocessing, model training, and evaluation in a structured pipeline.

### Forests, Boosts, Bags, Networks and More
- **Introduction to Advanced ML Techniques**
  - Gain an overview of advanced machine learning methods including random forests, boosting, bagging, and neural networks.

- **Practical 6: Random Forests**
  - Learn how to implement and evaluate random forests for classification and regression tasks.

- **Practical 7: Boosting Techniques**
  - Understand the concept of boosting and how it can improve model performance.
  - Apply boosting algorithms to various datasets.

- **Practical 8: Neural Networks**
  - Get introduced to the basics of neural networks.
  - Build simple neural network models for predictive tasks.

## Prerequisites
- Basic knowledge of R programming.
- Familiarity with fundamental statistical concepts.

